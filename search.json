[
  {
    "objectID": "probability.html",
    "href": "probability.html",
    "title": "Probability",
    "section": "",
    "text": "Probability is central to machine learning — particularly in generative models, classification, and Bayesian methods.\n\n\n\nDiscrete: Bernoulli, Binomial\nContinuous: Normal (Gaussian), Exponential\n\nExamples:\n\\[\nP(X = x) \\quad \\text{(discrete)}, \\qquad f_X(x) \\quad \\text{(continuous)}\n\\]\n\n\n\n\nExpected value:\n\n\\[\n\\mathbb{E}[X] = \\sum_x x P(X=x) \\quad \\text{or} \\quad \\mathbb{E}[X] = \\int x f_X(x)\\, dx\n\\]\n\nVariance:\n\n\\[\n\\mathrm{Var}(X) = \\mathbb{E}[(X - \\mathbb{E}[X])^2]\n\\]\n\n\n\nBayes’ Theorem lets us update what we believe about a situation after seeing new evidence.\nIt answers the question:\n&gt; “Given that something has happened (\\(B\\)), how likely is it that some other condition (\\(A\\)) was true?”\nThe formula is:\n\\[\nP(A \\mid B) = \\frac{P(B \\mid A) \\cdot P(A)}{P(B)}\n\\]\n\n\\(P(A \\mid B)\\): Posterior — the probability of \\(A\\) given that \\(B\\) happened\n\n\\(P(B \\mid A)\\): Likelihood — how likely is \\(B\\) if \\(A\\) is true?\n\n\\(P(A)\\): Prior — what we believed about \\(A\\) before seeing \\(B\\)\n\n\\(P(B)\\): Evidence — overall probability of \\(B\\) happening\n\n\n\n\nBayes’ Theorem is about updating your belief:\n\nStart with your prior belief (\\(P(A)\\))\nThen get some new evidence (\\(B\\))\nUpdate your belief based on how likely that evidence is under your assumption (\\(P(B \\mid A)\\))\n\n\n\n\n\nImagine a disease that affects 1% of the population.\nYou take a test that is: - 99% accurate for people with the disease: \\(P(\\text{Positive} \\mid \\text{Disease}) = 0.99\\) - False positive rate of 5%: \\(P(\\text{Positive} \\mid \\text{No Disease}) = 0.05\\)\nIf you test positive, what’s the chance you really have the disease?\nWe want to compute:\n\\[\nP(\\text{Disease} \\mid \\text{Positive}) = \\frac{P(\\text{Positive} \\mid \\text{Disease}) \\cdot P(\\text{Disease})}{P(\\text{Positive})}\n\\]\nLet’s plug in numbers: - \\(P(\\text{Disease}) = 0.01\\) - \\(P(\\text{Positive}) = P(\\text{Positive} \\mid \\text{Disease}) \\cdot P(\\text{Disease}) + P(\\text{Positive} \\mid \\text{No Disease}) \\cdot P(\\text{No Disease})\\) - \\(= 0.99 \\cdot 0.01 + 0.05 \\cdot 0.99 = 0.0594\\)\nSo: \\[\nP(\\text{Disease} \\mid \\text{Positive}) = \\frac{0.99 \\cdot 0.01}{0.0594} \\approx 0.1667\n\\]\nSurprising result: Even after testing positive, the chance you actually have the disease is only ~16.7% — because false positives are relatively common compared to actual cases.\n\n\n\n\nBayes’ Theorem is used in: - Medical diagnosis\n- Spam detection\n- Machine learning models (Naive Bayes)\n- Updating beliefs in AI systems\n\n\n\n\nSometimes you don’t need \\(P(B)\\). You just need to know:\n\\[\nP(A \\mid B) \\propto P(B \\mid A) \\cdot P(A)\n\\]\nThis is useful in classifiers like Naive Bayes, where comparing values is enough.\n\n\n\n\nProbability distributions describe how values of a random variable are distributed.\n\nDiscrete: Bernoulli, Binomial\nContinuous: Normal, Exponential\n\nPDF of normal distribution in 1D\n\\[\nf(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)\n\\]\n\n\nThe normal (Gaussian) distribution can be extended to multiple variables — for example, when \\(x\\) is a vector instead of just a number.\nWhen \\(x\\) is a vector in \\(\\mathbb{R}^d\\) (i.e., a list of \\(d\\) values), the multivariate Gaussian looks like:\n\\[\n\\mathcal{N}(x \\mid \\mu, \\Sigma) =\n\\frac{1}{(2\\pi)^{d/2} \\, |\\Sigma|^{1/2}}\n\\exp\\left( -\\frac{1}{2}(x - \\mu)^T \\Sigma^{-1}(x - \\mu) \\right)\n\\]\nWhat do all these symbols mean?\n\n\\(x\\): A \\(d\\)-dimensional vector (e.g., an image flattened into a 1D array)\n\\(\\mu\\): The mean vector (the “center” of the distribution)\n\\(\\Sigma\\): The \\(d \\times d\\) covariance matrix, which captures the spread and correlation of the variables\n\\(|\\Sigma|\\): The determinant of \\(\\Sigma\\), representing the volume of the distribution\n\\((2\\pi)^{d/2}\\): Comes from extending the 1D normalizing constant to \\(d\\) dimensions\n\\((x - \\mu)^T \\Sigma^{-1}(x - \\mu)\\): A generalized squared distance from \\(x\\) to the mean — see below!\n\n\n\n\n\n\n\nWhat’s the Mahalanobis Distance?\n\n\n\nThe term \\((x - \\mu)^T \\Sigma^{-1}(x - \\mu)\\) measures how far \\(x\\) is from the mean \\(\\mu\\), taking into account how spread out the data is in different directions. It’s like Euclidean distance, but adjusted for direction-dependent variance. The more noise (variance) in a direction, the less the distance is penalized in that direction.\n\n\n\n\n\nIf all variables are independent and have equal variance \\(\\sigma^2\\), then \\(\\Sigma = \\sigma^2 I\\) and the formula simplifies to:\n\\[\n\\mathcal{N}(x \\mid \\mu, \\sigma^2 I) =\n\\frac{1}{(2\\pi \\sigma^2)^{d/2}}\n\\exp\\left( -\\frac{1}{2\\sigma^2} \\|x - \\mu\\|^2 \\right)\n\\]\nThis looks more like the familiar 1D bell curve — but extended to \\(d\\) dimensions.\n\n\n\n\nUsed to estimate parameters of models:\n\\[\n\\hat{\\theta}_{\\text{MLE}} = \\arg\\max_\\theta P(D \\mid \\theta)\n\\]\n\n\n\nMeasures how one distribution diverges from another:\n\\[\nD_{\\text{KL}}(P \\parallel Q) = \\sum_x P(x) \\log \\frac{P(x)}{Q(x)}\n\\]\nUsed in training VAEs and information-theoretic learning.\n\n\n\n\nLogistic regression: based on Bernoulli distribution\n\nVariational autoencoders (VAEs): use probability distributions to encode data\n\nBayesian models: handle uncertainty via prior/posterior reasoning"
  },
  {
    "objectID": "probability.html#random-variables-and-distributions",
    "href": "probability.html#random-variables-and-distributions",
    "title": "Probability",
    "section": "",
    "text": "Discrete: Bernoulli, Binomial\nContinuous: Normal (Gaussian), Exponential\n\nExamples:\n\\[\nP(X = x) \\quad \\text{(discrete)}, \\qquad f_X(x) \\quad \\text{(continuous)}\n\\]"
  },
  {
    "objectID": "probability.html#expectation-and-variance",
    "href": "probability.html#expectation-and-variance",
    "title": "Probability",
    "section": "",
    "text": "Expected value:\n\n\\[\n\\mathbb{E}[X] = \\sum_x x P(X=x) \\quad \\text{or} \\quad \\mathbb{E}[X] = \\int x f_X(x)\\, dx\n\\]\n\nVariance:\n\n\\[\n\\mathrm{Var}(X) = \\mathbb{E}[(X - \\mathbb{E}[X])^2]\n\\]"
  },
  {
    "objectID": "probability.html#bayes-theorem",
    "href": "probability.html#bayes-theorem",
    "title": "Probability",
    "section": "",
    "text": "Bayes’ Theorem lets us update what we believe about a situation after seeing new evidence.\nIt answers the question:\n&gt; “Given that something has happened (\\(B\\)), how likely is it that some other condition (\\(A\\)) was true?”\nThe formula is:\n\\[\nP(A \\mid B) = \\frac{P(B \\mid A) \\cdot P(A)}{P(B)}\n\\]\n\n\\(P(A \\mid B)\\): Posterior — the probability of \\(A\\) given that \\(B\\) happened\n\n\\(P(B \\mid A)\\): Likelihood — how likely is \\(B\\) if \\(A\\) is true?\n\n\\(P(A)\\): Prior — what we believed about \\(A\\) before seeing \\(B\\)\n\n\\(P(B)\\): Evidence — overall probability of \\(B\\) happening\n\n\n\n\nBayes’ Theorem is about updating your belief:\n\nStart with your prior belief (\\(P(A)\\))\nThen get some new evidence (\\(B\\))\nUpdate your belief based on how likely that evidence is under your assumption (\\(P(B \\mid A)\\))\n\n\n\n\n\nImagine a disease that affects 1% of the population.\nYou take a test that is: - 99% accurate for people with the disease: \\(P(\\text{Positive} \\mid \\text{Disease}) = 0.99\\) - False positive rate of 5%: \\(P(\\text{Positive} \\mid \\text{No Disease}) = 0.05\\)\nIf you test positive, what’s the chance you really have the disease?\nWe want to compute:\n\\[\nP(\\text{Disease} \\mid \\text{Positive}) = \\frac{P(\\text{Positive} \\mid \\text{Disease}) \\cdot P(\\text{Disease})}{P(\\text{Positive})}\n\\]\nLet’s plug in numbers: - \\(P(\\text{Disease}) = 0.01\\) - \\(P(\\text{Positive}) = P(\\text{Positive} \\mid \\text{Disease}) \\cdot P(\\text{Disease}) + P(\\text{Positive} \\mid \\text{No Disease}) \\cdot P(\\text{No Disease})\\) - \\(= 0.99 \\cdot 0.01 + 0.05 \\cdot 0.99 = 0.0594\\)\nSo: \\[\nP(\\text{Disease} \\mid \\text{Positive}) = \\frac{0.99 \\cdot 0.01}{0.0594} \\approx 0.1667\n\\]\nSurprising result: Even after testing positive, the chance you actually have the disease is only ~16.7% — because false positives are relatively common compared to actual cases.\n\n\n\n\nBayes’ Theorem is used in: - Medical diagnosis\n- Spam detection\n- Machine learning models (Naive Bayes)\n- Updating beliefs in AI systems\n\n\n\n\nSometimes you don’t need \\(P(B)\\). You just need to know:\n\\[\nP(A \\mid B) \\propto P(B \\mid A) \\cdot P(A)\n\\]\nThis is useful in classifiers like Naive Bayes, where comparing values is enough."
  },
  {
    "objectID": "probability.html#probability-distributions",
    "href": "probability.html#probability-distributions",
    "title": "Probability",
    "section": "",
    "text": "Probability distributions describe how values of a random variable are distributed.\n\nDiscrete: Bernoulli, Binomial\nContinuous: Normal, Exponential\n\nPDF of normal distribution in 1D\n\\[\nf(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)\n\\]\n\n\nThe normal (Gaussian) distribution can be extended to multiple variables — for example, when \\(x\\) is a vector instead of just a number.\nWhen \\(x\\) is a vector in \\(\\mathbb{R}^d\\) (i.e., a list of \\(d\\) values), the multivariate Gaussian looks like:\n\\[\n\\mathcal{N}(x \\mid \\mu, \\Sigma) =\n\\frac{1}{(2\\pi)^{d/2} \\, |\\Sigma|^{1/2}}\n\\exp\\left( -\\frac{1}{2}(x - \\mu)^T \\Sigma^{-1}(x - \\mu) \\right)\n\\]\nWhat do all these symbols mean?\n\n\\(x\\): A \\(d\\)-dimensional vector (e.g., an image flattened into a 1D array)\n\\(\\mu\\): The mean vector (the “center” of the distribution)\n\\(\\Sigma\\): The \\(d \\times d\\) covariance matrix, which captures the spread and correlation of the variables\n\\(|\\Sigma|\\): The determinant of \\(\\Sigma\\), representing the volume of the distribution\n\\((2\\pi)^{d/2}\\): Comes from extending the 1D normalizing constant to \\(d\\) dimensions\n\\((x - \\mu)^T \\Sigma^{-1}(x - \\mu)\\): A generalized squared distance from \\(x\\) to the mean — see below!\n\n\n\n\n\n\n\nWhat’s the Mahalanobis Distance?\n\n\n\nThe term \\((x - \\mu)^T \\Sigma^{-1}(x - \\mu)\\) measures how far \\(x\\) is from the mean \\(\\mu\\), taking into account how spread out the data is in different directions. It’s like Euclidean distance, but adjusted for direction-dependent variance. The more noise (variance) in a direction, the less the distance is penalized in that direction.\n\n\n\n\n\nIf all variables are independent and have equal variance \\(\\sigma^2\\), then \\(\\Sigma = \\sigma^2 I\\) and the formula simplifies to:\n\\[\n\\mathcal{N}(x \\mid \\mu, \\sigma^2 I) =\n\\frac{1}{(2\\pi \\sigma^2)^{d/2}}\n\\exp\\left( -\\frac{1}{2\\sigma^2} \\|x - \\mu\\|^2 \\right)\n\\]\nThis looks more like the familiar 1D bell curve — but extended to \\(d\\) dimensions."
  },
  {
    "objectID": "probability.html#maximum-likelihood-estimation-mle",
    "href": "probability.html#maximum-likelihood-estimation-mle",
    "title": "Probability",
    "section": "",
    "text": "Used to estimate parameters of models:\n\\[\n\\hat{\\theta}_{\\text{MLE}} = \\arg\\max_\\theta P(D \\mid \\theta)\n\\]"
  },
  {
    "objectID": "probability.html#kl-divergence",
    "href": "probability.html#kl-divergence",
    "title": "Probability",
    "section": "",
    "text": "Measures how one distribution diverges from another:\n\\[\nD_{\\text{KL}}(P \\parallel Q) = \\sum_x P(x) \\log \\frac{P(x)}{Q(x)}\n\\]\nUsed in training VAEs and information-theoretic learning."
  },
  {
    "objectID": "probability.html#common-ml-applications",
    "href": "probability.html#common-ml-applications",
    "title": "Probability",
    "section": "",
    "text": "Logistic regression: based on Bernoulli distribution\n\nVariational autoencoders (VAEs): use probability distributions to encode data\n\nBayesian models: handle uncertainty via prior/posterior reasoning"
  },
  {
    "objectID": "calculus.html",
    "href": "calculus.html",
    "title": "Calculus",
    "section": "",
    "text": "This section covers core calculus concepts used in machine learning — especially in optimization, backpropagation, and probability.\n\n\nThe derivative of a function measures the rate of change:\n\\[\n\\frac{d}{dx} f(x)\n\\]\n\n\n\nUsed when dealing with multivariate functions:\n\\[\n\\frac{\\partial f}{\\partial x}, \\quad \\frac{\\partial f}{\\partial y}\n\\]\n\n\n\nFor a vector-valued function ( : ^n ^m ), the Jacobian is:\n\\[\nJ_{ij} = \\frac{\\partial f_i}{\\partial x_j}\n\\]\n\n\n\nSecond-order partial derivatives:\n\\[\nH_{ij} = \\frac{\\partial^2 f}{\\partial x_i \\partial x_j}\n\\]\nUsed in curvature analysis and second-order optimization.\n\n\n\nArea under a curve:\n\\[\n\\int_a^b f(x) \\, dx\n\\]\n\n\n\nA useful transformation:\n\\[\n\\int u \\, dv = uv - \\int v \\, du\n\\]"
  },
  {
    "objectID": "calculus.html#derivatives",
    "href": "calculus.html#derivatives",
    "title": "Calculus",
    "section": "",
    "text": "The derivative of a function measures the rate of change:\n\\[\n\\frac{d}{dx} f(x)\n\\]"
  },
  {
    "objectID": "calculus.html#partial-derivatives",
    "href": "calculus.html#partial-derivatives",
    "title": "Calculus",
    "section": "",
    "text": "Used when dealing with multivariate functions:\n\\[\n\\frac{\\partial f}{\\partial x}, \\quad \\frac{\\partial f}{\\partial y}\n\\]"
  },
  {
    "objectID": "calculus.html#jacobian-matrix",
    "href": "calculus.html#jacobian-matrix",
    "title": "Calculus",
    "section": "",
    "text": "For a vector-valued function ( : ^n ^m ), the Jacobian is:\n\\[\nJ_{ij} = \\frac{\\partial f_i}{\\partial x_j}\n\\]"
  },
  {
    "objectID": "calculus.html#hessian-matrix",
    "href": "calculus.html#hessian-matrix",
    "title": "Calculus",
    "section": "",
    "text": "Second-order partial derivatives:\n\\[\nH_{ij} = \\frac{\\partial^2 f}{\\partial x_i \\partial x_j}\n\\]\nUsed in curvature analysis and second-order optimization."
  },
  {
    "objectID": "calculus.html#integration",
    "href": "calculus.html#integration",
    "title": "Calculus",
    "section": "",
    "text": "Area under a curve:\n\\[\n\\int_a^b f(x) \\, dx\n\\]"
  },
  {
    "objectID": "calculus.html#integration-by-parts",
    "href": "calculus.html#integration-by-parts",
    "title": "Calculus",
    "section": "",
    "text": "A useful transformation:\n\\[\n\\int u \\, dv = uv - \\int v \\, du\n\\]"
  },
  {
    "objectID": "linear-algebra.html",
    "href": "linear-algebra.html",
    "title": "Linear Algebra",
    "section": "",
    "text": "This section covers essential linear algebra concepts that serve as the mathematical foundation for machine learning and deep learning.\n\n\n\nVector: A 1D array of numbers, often used to represent features.\nMatrix: A 2D array of numbers, common for representing datasets and weights.\n\nExample:\n\\[\n\\mathbf{x} = \\begin{bmatrix} 3 \\\\ 5 \\end{bmatrix}, \\quad\n\\mathbf{W} = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}\n\\]\n\n\n\nUsed in the forward pass of neural networks:\n\\[\n\\mathbf{y} = \\mathbf{W} \\mathbf{x}\n\\]\n\n\n\nMeasures projection or similarity:\n\\[\n\\mathbf{a} \\cdot \\mathbf{b} = \\sum_i a_i b_i\n\\]\n\n\n\n\nL2 Norm (Euclidean length):\n\n\\[\n\\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_i x_i^2}\n\\]\nUsed to compute distances and regularization penalties.\n\n\n\nThe determinant of a square matrix ( A ) is a scalar value:\n\\[\n\\det(A)\n\\]\nUsed in linear transformations and invertibility checks.\n\n\n\nThe trace of a square matrix is the sum of diagonal elements:\n\\[\n\\text{Tr}(A) = \\sum_i A_{ii}\n\\]\n\n\n\nUsed in PCA (dimensionality reduction):\n\\[\n\\mathbf{A} \\mathbf{v} = \\lambda \\mathbf{v}\n\\]\n\n\n\nUsed in matrix factorization and recommender systems:\n\\[\n\\mathbf{A} = \\mathbf{U} \\mathbf{\\Sigma} \\mathbf{V}^T\n\\]"
  },
  {
    "objectID": "linear-algebra.html#vectors-and-matrices",
    "href": "linear-algebra.html#vectors-and-matrices",
    "title": "Linear Algebra",
    "section": "",
    "text": "Vector: A 1D array of numbers, often used to represent features.\nMatrix: A 2D array of numbers, common for representing datasets and weights.\n\nExample:\n\\[\n\\mathbf{x} = \\begin{bmatrix} 3 \\\\ 5 \\end{bmatrix}, \\quad\n\\mathbf{W} = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}\n\\]"
  },
  {
    "objectID": "linear-algebra.html#matrix-multiplication",
    "href": "linear-algebra.html#matrix-multiplication",
    "title": "Linear Algebra",
    "section": "",
    "text": "Used in the forward pass of neural networks:\n\\[\n\\mathbf{y} = \\mathbf{W} \\mathbf{x}\n\\]"
  },
  {
    "objectID": "linear-algebra.html#dot-product",
    "href": "linear-algebra.html#dot-product",
    "title": "Linear Algebra",
    "section": "",
    "text": "Measures projection or similarity:\n\\[\n\\mathbf{a} \\cdot \\mathbf{b} = \\sum_i a_i b_i\n\\]"
  },
  {
    "objectID": "linear-algebra.html#norms-and-distances",
    "href": "linear-algebra.html#norms-and-distances",
    "title": "Linear Algebra",
    "section": "",
    "text": "L2 Norm (Euclidean length):\n\n\\[\n\\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_i x_i^2}\n\\]\nUsed to compute distances and regularization penalties."
  },
  {
    "objectID": "linear-algebra.html#determinant",
    "href": "linear-algebra.html#determinant",
    "title": "Linear Algebra",
    "section": "",
    "text": "The determinant of a square matrix ( A ) is a scalar value:\n\\[\n\\det(A)\n\\]\nUsed in linear transformations and invertibility checks."
  },
  {
    "objectID": "linear-algebra.html#trace",
    "href": "linear-algebra.html#trace",
    "title": "Linear Algebra",
    "section": "",
    "text": "The trace of a square matrix is the sum of diagonal elements:\n\\[\n\\text{Tr}(A) = \\sum_i A_{ii}\n\\]"
  },
  {
    "objectID": "linear-algebra.html#eigenvalues-and-eigenvectors",
    "href": "linear-algebra.html#eigenvalues-and-eigenvectors",
    "title": "Linear Algebra",
    "section": "",
    "text": "Used in PCA (dimensionality reduction):\n\\[\n\\mathbf{A} \\mathbf{v} = \\lambda \\mathbf{v}\n\\]"
  },
  {
    "objectID": "linear-algebra.html#singular-value-decomposition-svd",
    "href": "linear-algebra.html#singular-value-decomposition-svd",
    "title": "Linear Algebra",
    "section": "",
    "text": "Used in matrix factorization and recommender systems:\n\\[\n\\mathbf{A} = \\mathbf{U} \\mathbf{\\Sigma} \\mathbf{V}^T\n\\]"
  }
]